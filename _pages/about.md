---
permalink: /
title: "Greetings and Welcome to My Homepage"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


<font color='red'>I am on the academic job market for the 2025-2026 cycle. Would greatly appreciate it if you'd like to discuss any potential opportunities!</font>


## Biography
I am currently a Research Fellow at Nanyang Technological University, working with Prof. [Dacheng Tao](https://scholar.google.fr/citations?user=RwlJNLcAAAAJ&hl=en&oi=ao) and (previously) with Prof. [Tianwei Zhang](https://personal.ntu.edu.sg/tianwei.zhang/). Prior to this, I was a Research Professor (tenure-track) at Zhejiang University, where I received the Outstanding Junior Faculty Award (Qizhen Outstanding Young Scholar) and held appointments at both the State Key Laboratory of Blockchain and Data Security and HIC-ZJU. I received my Ph.D. degree with honors in Computer Science and Technology from Tsinghua University, advised by Prof. [Yong Jiang](https://www.sigs.tsinghua.edu.cn/jy/main.htm) and Prof. [Shu-Tao Xia](https://www.sigs.tsinghua.edu.cn/xst/main.htm), and my B.S. degree with honors in Applied Mathematics from Ningbo University (Yangming Innovation Class), where I was advised by Prof. [Lifeng Xi](http://math.nbu.edu.cn/info/1046/1098.htm). I also collaborated closely with Dr. [Zhifeng Li](https://scholar.google.fr/citations?user=VTrRNN4AAAAJ&hl=zh-CN) (at Tencent) and Prof. [Bo Li](https://scholar.google.com/citations?user=K8vJkTcAAAAJ&hl=en) (at UIUC) during my Ph.D. journey.

**My research centers on Responsible and Sustainable AI**, especially AI Risk Management and AI Copyright Protection. My long-term goal is to **advance responsible and sustainable development of AI models and systems, ultimately benefiting both society and humanity**. Recently, I focus more on **Trustworthy Generative AI** (*e.g.*, LLMs, Diffusion Models, AI Agents, Embodied AI, and Agent-based Social Simulation). I always **chase for simple yet effective methods** with deep insights and theoretical support. 

<strong><font color='blue'>For Potential Students and Collaborators</font></strong>: I am **always looking for highly self-motivated students and research interns** to join exciting research projects on Trustworthy ML and Responsible AI in our group. I will provide responsible and hands-on guidance. Besides, I am **always willing to work together on interesting projects with external collaborators**. Drop me an [email](mailto:liyiming.tech@gmail.com) if you are interested! 


## Selected Research

<div style="text-align: center;">
    <img src="/images/ResearchOverview_long.png" alt="Research Overview" width="80%">
</div>

<br>

(Generative) AI continues to advance rapidly, yet its *sustainable development* depends on addressing two foundational challenges: ensuring trustworthy large-scale deployment and supporting innovation through accountable use. My research advances a unified framework for a **sustainable AI ecosystem** by integrating **AI Risk Management** and **AI Copyright Protection** across the entire AI lifecycle (as outlined above and below). The first dimension focuses on *proactive risk sensing* and *effective risk mitigation* in both specialized and generative models, enabling secure and resilient operation under real-world conditions. The second dimension establishes a basis for fair competition and responsible innovation through *model copyright protection* and *data copyright protection*. Together, these pillars reinforce security, reliability, and fairness, thereby supporting the trustworthy and long-term advancement of modern AI technologies.


- **AI Risk Management**
  - **Risk Sensing**: [[S&P'26](https://arxiv.org/pdf/2507.16329), [NDSS'26 (a)](https://arxiv.org/pdf/2512.20168), [USENIX Security'26](https://arxiv.org/pdf/2504.20376), [USENIX Security'25](https://arxiv.org/pdf/2502.18943), [NDSS'26 (b)](https://arxiv.org/pdf/2508.06837), [S&P'25](https://arxiv.org/pdf/2503.09022), [NeurIPS'25](https://arxiv.org/pdf/2509.23871), [ICLR'25](https://openreview.net/pdf?id=p3mxzKmuZy), [TIFS'25](https://arxiv.org/pdf/2411.19479), [TDSC'25](https://www.researchgate.net/publication/376174078_Towards_Sample-specific_Backdoor_Attack_with_Clean_Labels_via_Attribute_Trigger), [CVPR'24](https://arxiv.org/pdf/2405.10612), [TIFS'24 (a)](https://www.researchgate.net/publication/370659402_Backdoor_Attack_with_Sparse_and_Invisible_Trigger), [ICCV'23](https://www.researchgate.net/publication/373049298_One-bit_Flip_is_All_You_Need_When_Bit-flip_Attack_Meets_Model_Training), [TIFS'24 (b)](https://www.researchgate.net/publication/372388876_Towards_Stealthy_Backdoor_Attacks_against_Speech_Recognition_via_Elements_of_Sound), [ICLR'23](https://openreview.net/pdf?id=_wSHsgrVali), [AAAI'23](https://ojs.aaai.org/index.php/AAAI/article/view/25154), [PR'23](https://www.sciencedirect.com/science/article/abs/pii/S0031320323002121), [ICLR'22](https://openreview.net/pdf?id=qSV5CuSaK_a), [ICASSP'21](https://arxiv.org/pdf/2010.11607.pdf), [ICCV'21](https://arxiv.org/pdf/2012.03816.pdf), [ICLR'21](https://arxiv.org/pdf/2102.10496.pdf), [ECCV'20 (Oral)](https://arxiv.org/abs/2004.07955)] 
  - **Risk Mitigation**: [[NeurIPS'25](https://arxiv.org/pdf/2507.16302), [ICLR'25 (a)](https://openreview.net/pdf?id=4IYdCws9fc), [ICLR'25 (b)](https://openreview.net/pdf?id=EbxYDBhE3S), [ICML'25](https://liyiming.tech/publications/), [ACL'25 (a)](https://arxiv.org/pdf/2411.12701), [ACL'25 (b)](https://arxiv.org/pdf/2412.14959), [ICML'24 (a)](https://arxiv.org/pdf/2405.09786), [ICML'24 (b)](https://openreview.net/pdf?id=CEfr3h68KU), [CVPR'25](https://arxiv.org/pdf/2405.12725), [ICLR'24 (a) (Spotlight)](https://openreview.net/forum?id=Tw9wemV6cb), [ICLR'24 (b)](https://openreview.net/forum?id=s56xikpD92), [IJCAI'24](https://doi.org/10.24963/ijcai.2024/933), [IJCV'24](https://link.springer.com/article/10.1007/s11263-024-02103-w), [NeurIPS'23](https://arxiv.org/pdf/2310.18633.pdf), [ICLR'23](https://openreview.net/pdf?id=o0LFPcoFKnr), [ICLR'22](https://openreview.net/pdf?id=TySnJ-0RdKI), [PR'22](https://www.sciencedirect.com/science/article/abs/pii/S0031320321006488)]

- **AI Copyright Protection**
  - **Model Copyright**: [[WWW'26](https://arxiv.org/pdf/2510.06605), [NDSS'25](https://arxiv.org/pdf/2405.04825), [CVPR'25](https://arxiv.org/pdf/2412.04852), [ICLR'25](https://openreview.net/pdf?id=uzz3qAYy0D), [TPAMI'25](https://arxiv.org/pdf/2208.02820.pdf), [ECCV'24](https://arxiv.org/pdf/2404.02697), [ICCV'23](https://www.researchgate.net/publication/373367424_Towards_Robust_Model_Watermark_via_Reducing_Parametric_Vulnerability), [AAAI'22](https://arxiv.org/pdf/2112.03476.pdf)]
  - **Data Copyright**: [[WWW'26](https://arxiv.org/pdf/2510.15303), [USENIX Security'25](https://arxiv.org/pdf/2502.18943), [S&P'25 (a)](https://arxiv.org/pdf/2410.10437), [S&P'25 (b)](https://arxiv.org/pdf/2503.09022), [TPAMI'25](https://github.com/THUYimingLi/THUYimingLi.github.io/blob/master/_pages), [TIFS'25](https://arxiv.org/pdf/2505.02824), [NeurIPS'24](https://openreview.net/pdf?id=Eyyt3ZmNV6), [TIFS'24](https://www.researchgate.net/publication/383060790_PointNCBW_Towards_Dataset_Ownership_Verification_for_Point_Clouds_via_Negative_Clean-label_Backdoor_Watermark), [TIFS'23 (TOP-25 Papers)](https://www.researchgate.net/publication/369559541_Black-box_Dataset_Ownership_Verification_via_Backdoor_Watermarking), [NeurIPS'23](https://www.researchgate.net/publication/374440504_Domain_Watermark_Effective_and_Harmless_Dataset_Copyright_Protection_is_Closed_at_Hand), [PR'22](https://www.sciencedirect.com/science/article/pii/S0031320321005112), [NeurIPS'22 (Oral)](https://www.researchgate.net/publication/363766436_Untargeted_Backdoor_Watermark_Towards_Harmless_and_Stealthy_Dataset_Copyright_Protection)]




## News
<div style="max-height: 250px; overflow-y: auto;">
<ul>
  <li>01/2026: Three papers about LLM Copyright and Agent for Social Simulation is accepted by WWW 2026.</li>
  <li>12/2025: One paper about Multi-turn Jailbreak Attack against Commercial T2I Systems is accepted by USENIX Security 2026.</li>
  <li>12/2025: One paper about Jailbreaking Commercial MLLM is accepted by NDSS 2026.</li>
  <li>11/2025: One paper about Unlearnable Examples is accepted by IEEE TPAMI 2025.</li>
  <li>11/2025: One paper about T2I Prompt Stealing Attack is accepted by NDSS 2026.</li>
  <li>11/2025: One paper about T2I Dataset Ownership Verification is accepted by IEEE TIFS.</li>
  <li>11/2025: One paper about MLLM Backdoor Defense is accepted by AAAI 2026.</li>
  <li>09/2025: I am invited to serve as the Program Committee for CCS 2026.</li>
  <li>09/2025: I was recognized in the 2025 Elsevier–Stanford World’s Top 2% Scientists list.</li>
  <li>09/2025: Four papers about MLLM Security, Conditional Backdoor Attack, and Safety-driven Unlearning for T2I Diffusion Models are accepted by NeurIPS 2025.</li>
  <li>09/2025: One paper about Backdoor Defense is accepted by IEEE TIFS.</li>
  <li>09/2025: One paper about Red Teaming T2I Diffusion Models is accepted by IEEE S&P 2026.</li>
  <li>09/2025: I am invited to serve as the Area Chair for CVPR 2026.</li>
  <li>08/2025: I am invited to serve as the Area Chair for ICLR 2026.</li>
  <li>08/2025: I will serve as the Consulting Area Editor for IEEE TIFS.</li>
  <li>07/2025: One paper about Backdoor Defense is accepted by IEEE TIFS.</li>
  <li>05/2025: Two papers about LLM Safety and Security are accepted by ACL (Main Track) 2025.</li>
  <li>04/2025: I am invited to serve as the Area Chair for NeurIPS 2025.</li>
  <li>03/2025: One paper about Backdoor Attack is accepted by IEEE TDSC.</li>
  <li>03/2025: One paper about Prompt Inversion Attack is accepted by IEEE S&P 2025.</li>
  <li>02/2025: One paper about T2I Model Watermarking is accepted by CVPR 2025.</li>
  <li>02/2025: Our paper about Model Ownership Verification is accepted by IEEE TPAMI.</li>
  <li>01/2025: One paper about Membership Inference Attack is accepted to USENIX Security 2025.</li>
  <li>01/2025: Four papers about GenAI Security, GenAI Copyright, and Backdoor Defenses are accepted to ICLR 2025.</li>
  <li>01/2025: I will serve as Associate Editor for Pattern Recognition.</li>
</ul>
</div>



## Useful Resources

[<font color='orange'>Perspective: Rethinking Data Protection in the (Generative) Artificial Intelligence Era</font>](http://arxiv.org/abs/2507.03034)

[<font color='orange'>Survey and Benchmark for Fingerprinting-based LLM's Copyright Auditing</font>](https://arxiv.org/pdf/2508.19843), as well as its [<font color='orange'>Toolbox</font>](https://github.com/shaoshuo-ss/LeaFBench)

[<font color='orange'>Survey and Benchmark for for Dataset Auditing</font>](https://arxiv.org/pdf/2507.05622), as well as its [<font color='orange'>Toolbox</font>](https://github.com/shaoshuo-ss/DATABench)

[<font color='orange'>Survey</font>](https://www.researchgate.net/publication/343006441_Backdoor_Learning_A_Survey), [<font color='orange'>Toolbox</font>](https://github.com/THUYimingLi/BackdoorBox), and [<font color='orange'>GitHub Resources Repo</font>](https://github.com/THUYimingLi/backdoor-learning-resources) about Backdoor Learning.


[**A Brief Bio**](): Dr. Yiming Li is currently a Research Fellow at Nanyang Technological University. Prior to this, he was a Research Professor (tenure-track) at Zhejiang University, where he received the Outstanding Junior Faculty Award and held appointments at both the State Key Laboratory of Blockchain and Data Security and HIC-ZJU. He obtained his Ph.D. in Computer Science and Technology (with honors) from Tsinghua University and his B.S. in Mathematics (with honors) from Ningbo University. His research centers on Trustworthy Machine Learning and Responsible Artificial Intelligence, with a particular focus on AI Security, AI Safety, and AI Copyright Protection. His work has been published in leading venues, such as IEEE S&P, USENIX Security, NDSS, ICML, NeurIPS, ICLR, CVPR, ICCV, IEEE TPAMI, IEEE TIFS, and IEEE TDSC. He serves as the Consulting Area Editor for IEEE TIFS, Associate Editor for Pattern Recognition, Area Chair for CVPR, ICLR, ICML, NeurIPS, and ACM Multimedia, Senior Program Committee Member for AAAI and IJCAI, and Program Committee Member for CCS, EuroS&P, and IEEE SaTML. He also regularly reviews for leading journals such as IEEE TPAMI, IJCV, IEEE TIFS, and IEEE TDSC. His research has been featured in major media outlets, including IEEE Spectrum and MIT Technology Review. He is the recipient of several prestigious honors, such as the Best Paper Award at PAKDD, the Rising Star Award at WAIC, the KAUST Rising Stars in AI, and the DAAD AInet Fellowship, as well as inclusion in the 2025 Elsevier–Stanford World's Top 2% Scientists list.




